from atm import ATM
from atm import Model
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from autosklearn.classification import AutoSklearnClassifier
from sklearn.preprocessing import LabelEncoder
from utils import Thread
import os
import signal
import errno
from functools import wraps
import time

global data
global time_limit


def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):
    def decorator(func):
        def _handle_timeout(signum, frame):
            f2 = open('/mnt/disk/benchmark/failed.txt', 'a')
            f2.write(data[0]+" "+str(time_limit)+" timeout"+"\n")
            f2.close()

            with open('/mnt/disk/benchmark/Datasets/test.txt', 'w') as fout:
                for each in data[1:]:
                    fout.write(each+"\n")

            os.system('sudo reboot')

        def wrapper(*args, **kwargs):
            signal.signal(signal.SIGALRM, _handle_timeout)
            signal.alarm(seconds)
            try:
                result = func(*args, **kwargs)
            finally:
                signal.alarm(0)
            return result

        return wraps(func)(wrapper)

    return decorator


class ATMbenchmark:
    out = 0
    rslt = None
    fail = ""

    #return train,test
    def _load_data(self, dataset_file, dataset_test_file=None, split=0.75):
            if dataset_test_file is None:
                data = pd.read_csv(dataset_file, na_values='?')
                train, test = train_test_split(data, train_size=split)
                print(len(train), len(test))
            else:
                train, test = [pd.read_csv(file, na_values='?') for file in [
                    dataset_file, dataset_test_file]]
                data = pd.concat([train, test])

            self.categorical_ = data.select_dtypes(['object']).columns
            lab_encs = {col: LabelEncoder().fit(
                data[col].astype('str')) for col in self.categorical_}

            for col in self.categorical_:
                train[col] = lab_encs[col].transform(train[col].astype('str'))
                test[col] = lab_encs[col].transform(test[col].astype('str'))

            y_col = data.columns[-1]
            return train.drop(y_col, axis=1), train[y_col], test.drop(y_col, axis=1), test[y_col]

    def eval_y(self, y, predictions):
            return {
                'accuracy': accuracy_score(y, predictions),
                'precision': precision_score(y, predictions, average='weighted'),
                'recall': recall_score(y, predictions, average='weighted'),
                'f1score': f1_score(y, predictions, average='weighted')
            }

    def run_ATM(self, train_path, test_path, time_limit, dataset_name, metric="accuracy"):
        self.dataset_name = dataset_name
        self.time_limit = time_limit
        self.metric = metric
        t = int(self.time_limit * 60 * 1.1)
        self.fail = ""
        #t=5

        @timeout(t)
        def run(train_path, test_path, time_limit, dataset_name, metric="accuracy"):
            '''initialization
            '''
            atm = ATM()
            print(os.path.isfile(os.path.abspath(train_path)))
            rslt = atm.run(train_path=train_path,
                           test_path=test_path,
                           budget=time_limit,
                           budget_type="walltime",
                           metric=metric)  # f1 or accuracy

            return rslt
        try:
            self.rslt = run(train_path, test_path, time_limit,
                            dataset_name, metric="accuracy")
        except:
            self.rslt = None
            self.fail = "error"

    def evaluate(self):
        if self.rslt:
            clasr = self.rslt.get_best_classifier()
        else:
            self.out = 0
            return 0

        if not clasr:
            self.out = 0
            return 0
        print(clasr)
        classifier = clasr.load_model()
        '''evaluation
        '''
        data = pd.read_csv(test_path).dropna(how='any')
        predictions = classifier.predict(data)
        y = data['class']
        eval_res = self.eval_y(y, predictions)

        print(eval_res)
        '''logging
        '''
        log = [str(clasr), str(eval_res)]
        log_file = "/mnt/disk/benchmark/ATM-"+self.dataset_name + \
            "-"+str(self.time_limit)+"-"+self.metric+".txt"
        open(log_file, mode='w', encoding="utf-8").write(str(log))
        self.out = 1
        return 1


atmbench = ATMbenchmark()
time_limit = 240

with open('/mnt/disk/benchmark/Datasets/test.txt', 'r') as fin:
    data = fin.read().splitlines()

if len(data) <= 0:
    exit()

#atmbench.load_data(
#    "/mnt/disk/benchmark/Datasets/Datasets_Full/"+data[0]+".csv")

X_train, y_train, X_test, y_test = atmbench._load_data(
    "/mnt/disk/benchmark/Datasets/Datasets_Full/"+data[0]+".csv")


y_test = y_test.rename("class")
y_train = y_train.rename("class")

X_test["class"] = y_test
X_train["class"] = y_train

X_train.to_csv('/mnt/disk/benchmark/Datasets/train.csv')
X_test.to_csv('/mnt/disk/benchmark/Datasets/test.csv')

result = {}
train_path = "/mnt/disk/benchmark/Datasets/train.csv"
test_path = "/mnt/disk/benchmark/Datasets/test.csv"
dataset_name = data[0]
atmbench.run_ATM(train_path, test_path, time_limit, dataset_name)
#atmbench.run_ATM(train_path, test_path, time_limit, dataset_name)
out = atmbench.evaluate()


if atmbench.out != 1:
    f2 = open('/mnt/disk/benchmark/failed.txt', 'a')
    f2.write(data[0]+" "+str(time_limit)+" "+atmbench.fail + "\n")
    f2.close()

with open('/mnt/disk/benchmark/Datasets/test.txt', 'w') as fout:
    for each in data[1:]:
        fout.write(each+"\n")

os.system('sudo reboot')
